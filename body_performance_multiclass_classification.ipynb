{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d30cdfed-8af8-4614-a460-888e5988d80f",
   "metadata": {},
   "source": [
    "**Body Performance Multiclass classification using ANNs**\n",
    "==========================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fce72ca-958b-4588-b832-6dd9c70574b7",
   "metadata": {},
   "source": [
    "**Tom Wright-Anderson**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32de88e1-bb48-4e04-aec1-b1ea1da36491",
   "metadata": {},
   "source": [
    "Dataset: https://www.kaggle.com/datasets/kukuroo3/body-performance-data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ec355a-4ba9-434b-9e57-af5c5aedb971",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a026b65d-f1f8-451a-b640-cb995e8bd899",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('C:/Users/tomwr/Datascience/Datasets/Tabular/body_performance_multiclass_classification.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb50f9f-337c-40a3-bb13-b1174190b550",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a08245f-8cd0-4e3f-a155-0db82656b75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Changing datatypes\n",
    "data['age'] = data['age'].astype('int64')\n",
    "data['diastolic'] = data['diastolic'].astype('int64')\n",
    "data['systolic'] = data['systolic'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce6ba7d-bd2f-4281-b175-3ab149eda17c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature engineering - extra features\n",
    "\n",
    "data['BMI'] = data['weight_kg'] / (data['height_cm']/100)**2\n",
    "data['relative_jump'] = data['broad jump_cm'] / data['height_cm']\n",
    "\n",
    "data['dummy'] = 1 # Dummy column for violinplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ffb6709-6805-4440-a1da-10b73fb8e28b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9203be8-6183-49e9-9057-2c9cc04001de",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['class'].value_counts() # Pretty much balanced classes so no class weighting needed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f0358aa-7c0c-413d-8557-8961ca93d39f",
   "metadata": {},
   "source": [
    "**Violin plots of all variables, split coloured by gender**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ccb6511-b30d-4398-b06b-127c671b54bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows = 4,\n",
    "                       ncols = 3,\n",
    "                       sharex = True,\n",
    "                       sharey = False\n",
    "                      )\n",
    "fig.set_size_inches(16,16)\n",
    "\n",
    "plt.suptitle('Body Performance Metrics by Gender',\n",
    "             fontweight = 'bold'\n",
    "            )\n",
    "\n",
    "sns.violinplot(data = data, x = 'dummy', y = 'height_cm', hue = 'gender', split = True, ax = ax[0, 0])\n",
    "ax[0, 0].set_title('Height')\n",
    "ax[0, 0].set_ylabel('Height (cm)')\n",
    "\n",
    "sns.violinplot(data = data, x = 'dummy', y = 'weight_kg', hue = 'gender', split = True, ax = ax[0, 1])\n",
    "ax[0, 1].set_title('Weight')\n",
    "ax[0, 1].set_ylabel('Weight (kg)')\n",
    "\n",
    "sns.violinplot(data = data, x = 'dummy', y = 'body fat_%', hue = 'gender', split = True, ax = ax[0, 2])\n",
    "ax[0, 2].set_title('Body Fat')\n",
    "ax[0, 2].set_ylabel('Body fat (%)')\n",
    "\n",
    "sns.violinplot(data = data, x = 'dummy', y = 'diastolic', hue = 'gender', split = True, ax = ax[1, 0])\n",
    "ax[1, 0].set_title('Diastolic pressure minimum')\n",
    "ax[1, 0].set_ylabel('Diastolic')\n",
    "\n",
    "sns.violinplot(data = data, x = 'dummy', y = 'systolic', hue = 'gender', split = True, ax = ax[1, 1])\n",
    "ax[1, 1].set_title('Systolic pressure minimum')\n",
    "ax[1, 1].set_ylabel('Systolic')\n",
    "\n",
    "sns.violinplot(data = data, x = 'dummy', y = 'gripForce', hue = 'gender', split = True, ax = ax[1, 2])\n",
    "ax[1, 2].set_title('Grip strength')\n",
    "ax[1, 2].set_ylabel('Grip strength (kg)')\n",
    "\n",
    "sns.violinplot(data = data, x = 'dummy', y = 'sit and bend forward_cm', hue = 'gender', split = True, ax = ax[2, 0], cut = 0)\n",
    "ax[2, 0].set_title('Sit and bend forward reach')\n",
    "ax[2, 0].set_ylabel('Reach (cm)')\n",
    "\n",
    "sns.violinplot(data = data, x = 'dummy', y = 'sit-ups counts', hue = 'gender', split = True, ax = ax[2, 1])\n",
    "ax[2, 1].set_title('Sit-up count')\n",
    "ax[2, 1].set_ylabel('Number of sit-ups')\n",
    "\n",
    "sns.violinplot(data = data, x = 'dummy', y = 'broad jump_cm', hue = 'gender', split = True, ax = ax[2, 2])\n",
    "ax[2, 2].set_title('Broad jump length')\n",
    "ax[2, 2].set_ylabel('Jump length (cm)')\n",
    "\n",
    "sns.violinplot(data = data, x = 'dummy', y = 'BMI', hue = 'gender', split = True, ax = ax[3, 0])\n",
    "ax[3, 0].set_title('BMI')\n",
    "ax[3, 0].set_ylabel('BMI Value')\n",
    "\n",
    "sns.violinplot(data = data, x = 'dummy', y = 'relative_jump', hue = 'gender', split = True, ax = ax[3, 1])\n",
    "ax[3, 1].set_title('Relative Jump')\n",
    "ax[3, 1].set_ylabel('Jump relative to height ratio')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for ax in ax.flatten():\n",
    "    plt.sca(ax)\n",
    "    plt.tick_params('x',\n",
    "                color = 'white',\n",
    "                labelcolor = 'white')\n",
    "    plt.xlabel('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3892ade9-6435-4bc1-a657-ea61f186a1c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Turn categorical variables into numerical\n",
    "\n",
    "data['gender'].replace(['M', 'F'], [0, 1], inplace = True)\n",
    "#data['class'].replace(['A', 'B', 'C', 'D'], [0, 1, 2, 3], inplace = True)\n",
    "data = pd.get_dummies(data = data, columns = ['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7481f18-27a7-4588-bf44-113ffd208376",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing dummy\n",
    "del data['dummy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81fd16c1-4bc8-4564-a877-772f0a75d651",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91bc1311-fc13-40a2-a5a3-2cfacb7908aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting dataset\n",
    "y = data[['class_A', 'class_B', 'class_C', 'class_D']].values\n",
    "#X = data.loc[:, data.columns != ['class_A', 'class_B', 'class_C', 'class_D']].values\n",
    "X = data.iloc[:, :13]\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.15)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d17315-8fdd-492d-b256-6c60495f4fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scaling dataset using RobustScaler as some outliers \n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "robustscaler = RobustScaler(quantile_range = (15, 85))\n",
    "\n",
    "X_train = robustscaler.fit_transform(X_train)\n",
    "X_val = robustscaler.transform(X_val)\n",
    "X_test = robustscaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "439e61a7-c581-4209-8a43-b3c197ae3c3f",
   "metadata": {},
   "source": [
    "**Model creation - Tensorflow / Keras**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c38b1cff-2a76-463d-aafd-4bdddeb59088",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Input, Dropout, BatchNormalization, Activation\n",
    "from keras.optimizers import Adam, Nadam, Adadelta\n",
    "from keras.metrics import SparseCategoricalCrossentropy, KLDivergence, CategoricalCrossentropy\n",
    "from keras.losses import SparseCategoricalCrossentropy, CategoricalCrossentropy\n",
    "from keras.layers.activation import *\n",
    "from keras.callbacks import ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f20212b7-e5a1-4fc7-bd1d-a4d7dbfc3ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function for displaying model training metrics and validation performance\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def display_model_metrics(name, history):\n",
    "    history_df = pd.DataFrame(history.history)\n",
    "    \n",
    "    x_axis = np.arange(1, len(history_df) + 1, 1)\n",
    "    \n",
    "    fig, ax = plt.subplots(nrows = 1,\n",
    "                           ncols = 2,\n",
    "                           sharex = True,\n",
    "                           sharey = False\n",
    "                          )\n",
    "    fig.set_size_inches(10, 10) \n",
    "    ax[0].plot(x_axis, history_df['categorical_crossentropy'], label = 'categorical crossentropy')\n",
    "    ax[0].plot(x_axis, history_df['val_categorical_crossentropy'], label = 'validation categorical crossentropy')\n",
    "    ax[0].set_title('Loss')\n",
    "    ax[0].set_ylabel('Categorical crossentropy')\n",
    "    ax[0].set_xlabel('Epochs')\n",
    "    \n",
    "    \n",
    "    ax[1].plot(x_axis, history_df['kullback_leibler_divergence'], label = 'KLDivergence')\n",
    "    ax[1].plot(x_axis, history_df['val_kullback_leibler_divergence'], label = 'Validation KLDivergence')\n",
    "    ax[1].set_title('KLDivergence')\n",
    "    ax[1].set_ylabel('KLDivergence')\n",
    "    ax[1].set_xlabel('Epochs')\n",
    "    \n",
    "    plt.suptitle(f'{name}\\'s performance metrics',\n",
    "                 fontweight = 'bold'\n",
    "                )\n",
    "    \n",
    "    for ax in ax.flatten():\n",
    "        ax.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2086913d-f69a-44c6-bedf-71640b5de93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function for creating and visualizing a confusion matrix\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "def display_confusion_matrix(X_val, X_test, y_val, y_test, model):\n",
    "    \n",
    "    #Validation\n",
    "    y_val_labels = np.argmax(y_val, axis = 1)\n",
    "    \n",
    "    val_pred_proba = model.predict(X_val)\n",
    "    val_pred_classes = np.zeros_like(y_val)\n",
    "    val_pred_max_indices = np.argmax(val_pred_proba, axis = 1)\n",
    "    val_pred_classes[np.arange(len(val_pred_proba)), val_pred_max_indices] = 1\n",
    "    single_val_pred_classes = np.argmax(val_pred_classes, axis = 1)\n",
    "    \n",
    "    \n",
    "    #Testing\n",
    "    y_test_labels = np.argmax(y_test, axis = 1)\n",
    "    \n",
    "    test_pred_proba = model.predict(X_test)\n",
    "    test_pred_classes = np.zeros_like(y_test)\n",
    "    test_pred_max_indices = np.argmax(test_pred_proba, axis = 1)\n",
    "    test_pred_classes[np.arange(len(test_pred_proba)), test_pred_max_indices] = 1\n",
    "    single_test_pred_classes = np.argmax(test_pred_classes, axis = 1)\n",
    "    \n",
    "    #Confusion matrices\n",
    "    val_cm = confusion_matrix(y_val_labels, single_val_pred_classes, normalize = 'all')\n",
    "    test_cm = confusion_matrix(y_test_labels, single_test_pred_classes, normalize = 'all')\n",
    "    \n",
    "    \n",
    "    #Confusion matrices displays\n",
    "    val_cm_display = ConfusionMatrixDisplay(val_cm, display_labels = ['Class A', 'Class B', 'Class C', 'Class D'])\n",
    "    test_cm_display = ConfusionMatrixDisplay(test_cm, display_labels = ['Class A', 'Class B', 'Class C', 'Class D'])\n",
    "    \n",
    "    \n",
    "    \n",
    "    val_cm_display.plot()\n",
    "    \n",
    "    test_cm_display.plot()\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f739cc-63f7-4ed7-94b3-301db543ace7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create some callbacks\n",
    "from keras.callbacks import *\n",
    "\n",
    "reduce_lr_on_plateau_half = ReduceLROnPlateau(monitor = 'val_loss',\n",
    "                                              patience = 20,\n",
    "                                              factor = 0.5) #Halved\n",
    "\n",
    "reduce_lr_on_plateau_f10 = ReduceLROnPlateau(monitor = 'val_loss',\n",
    "                                             patience = 20,\n",
    "                                             factor = 0.1)\n",
    "\n",
    "early_stopping_50 = EarlyStopping(monitor = 'val_loss',\n",
    "                                  patience = 50)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d24f8e6b-e884-42c9-b4e0-56f166464e35",
   "metadata": {},
   "source": [
    "**Methodology**\n",
    "\n",
    "Making incremental changes in model structure and hyperparameters to narrow down to an optimal model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f652338b-b21b-4c0b-b48b-acda40a0446d",
   "metadata": {},
   "outputs": [],
   "source": [
    "m1_name = 'm1_TF_3x16'\n",
    "m1_epochs = 5\n",
    "\n",
    "m1 = Sequential([\n",
    "    BatchNormalization(),\n",
    "    \n",
    "    Dense(units = 16, kernel_initializer = 'he_normal'),\n",
    "    Activation('relu'),\n",
    "    Dropout(0.1),\n",
    "    \n",
    "    Dense(units = 16, kernel_initializer = 'he_normal'),\n",
    "    Activation('relu'),\n",
    "    Dropout(0.1),\n",
    "    \n",
    "    Dense(units = 16, kernel_initializer = 'he_normal'),\n",
    "    Activation('relu'),\n",
    "    BatchNormalization(),\n",
    "    \n",
    "    Dense(units = 4, activation = Softmax())\n",
    "])\n",
    "\n",
    "m1.compile(loss = CategoricalCrossentropy(),\n",
    "           optimizer = Adam(),\n",
    "           metrics = [CategoricalCrossentropy(), KLDivergence()]\n",
    "          )\n",
    "m1_history = m1.fit(X_train, y_train,\n",
    "                    validation_data = (X_val, y_val),\n",
    "                    epochs = m1_epochs\n",
    "                   )\n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aefb0bf-14ce-4a44-b080-db7df17d66cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_model_metrics(m1_name, m1_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd155226-d0e8-4ed1-bd82-486cd8e14b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_confusion_matrix(X_val, X_test, y_val, y_test, m1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "239aac48-4dbd-4718-ac2f-63c27e014c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "m2_name = 'm2_TF_4x8'\n",
    "m2_epochs = 25\n",
    "\n",
    "m2 = Sequential([\n",
    "    BatchNormalization(),\n",
    "    Dense(8, kernel_initializer = 'he_normal'),\n",
    "    Activation('relu'),\n",
    "    Dense(8, kernel_initializer = 'he_normal'),\n",
    "    Activation('relu'),\n",
    "    Dense(8, kernel_initializer = 'he_normal'),\n",
    "    Activation('relu'),\n",
    "    Dense(8, kernel_initializer = 'he_normal'),\n",
    "    Activation('relu'),\n",
    "    BatchNormalization(),\n",
    "    \n",
    "    Dense(4, activation = 'softmax')\n",
    "])\n",
    "\n",
    "m2.compile(loss = 'categorical_crossentropy',\n",
    "           optimizer = Adadelta(),\n",
    "           metrics = [CategoricalCrossentropy(), KLDivergence()]\n",
    "          )\n",
    "m2_lr_on_plateau = ReduceLROnPlateau(monitor = 'val_loss',\n",
    "                                     patience = 25,\n",
    "                                     factor = 0.9)\n",
    "\n",
    "m2_history = m2.fit(X_train, y_train,\n",
    "                    validation_data = (X_val, y_val),\n",
    "                    epochs = m2_epochs,\n",
    "                   callbacks = [m2_lr_on_plateau])\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90af1a67-6e10-4e38-929b-54136a226ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_model_metrics(m2_name, m2_history)\n",
    "\n",
    "display_confusion_matrix(X_val, X_test, y_val, y_test, m2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b90c2fd-658f-494d-bdc8-bbcfcdced15f",
   "metadata": {},
   "outputs": [],
   "source": [
    "m3_name = 'm3_TF_3x16_reg'\n",
    "m3_epochs = 250\n",
    "\n",
    "m3 = Sequential([\n",
    "    BatchNormalization(),\n",
    "    \n",
    "    Dense(units = 16, kernel_initializer = 'he_normal', kernel_regularizer = 'l2'),\n",
    "    Activation('relu'),\n",
    "    \n",
    "    Dense(units = 16, kernel_initializer = 'he_normal', kernel_regularizer = 'l2'),\n",
    "    Activation('relu'),\n",
    "    \n",
    "    Dense(units = 16, kernel_initializer = 'he_normal', kernel_regularizer = 'l2'),\n",
    "    Activation('relu'),\n",
    "    BatchNormalization(),\n",
    "    \n",
    "    Dense(units = 4, activation = Softmax())\n",
    "])\n",
    "\n",
    "m3.compile(loss = CategoricalCrossentropy(),\n",
    "           optimizer = Adam(),\n",
    "           metrics = [CategoricalCrossentropy(), KLDivergence()]\n",
    "          )\n",
    "m3_history = m3.fit(X_train, y_train,\n",
    "                    validation_data = (X_val, y_val),\n",
    "                    epochs = m3_epochs,\n",
    "                    callbacks = [reduce_lr_on_plateau_half, early_stopping_50]\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0070d1c9-8a90-4218-952f-3d40cede3581",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_model_metrics(m3_name, m3_history)\n",
    "\n",
    "display_confusion_matrix(X_val, X_test, y_val, y_test, m3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c2b82e2-5dee-4787-8507-5e40029ff173",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Same as Model 3 but using ELU for activation rather than ReLU - supposedly more effective.\n",
    "\n",
    "\n",
    "m4_name = 'm4_TF_3x16_reg'\n",
    "m4_epochs = 250\n",
    "\n",
    "m4 = Sequential([\n",
    "    BatchNormalization(),\n",
    "    \n",
    "    Dense(units = 16, kernel_initializer = 'he_normal', kernel_regularizer = 'l2'),\n",
    "    Activation('elu'),\n",
    "    \n",
    "    Dense(units = 16, kernel_initializer = 'he_normal', kernel_regularizer = 'l2'),\n",
    "    Activation('elu'),\n",
    "    \n",
    "    Dense(units = 16, kernel_initializer = 'he_normal', kernel_regularizer = 'l2'),\n",
    "    Activation('elu'),\n",
    "    BatchNormalization(),\n",
    "    \n",
    "    Dense(units = 4, activation = Softmax())\n",
    "])\n",
    "\n",
    "m4.compile(loss = CategoricalCrossentropy(),\n",
    "           optimizer = Adam(),\n",
    "           metrics = [CategoricalCrossentropy(), KLDivergence()]\n",
    "          )\n",
    "m4_history = m4.fit(X_train, y_train,\n",
    "                    validation_data = (X_val, y_val),\n",
    "                    epochs = m4_epochs,\n",
    "                    callbacks = [reduce_lr_on_plateau_half, early_stopping_50]\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "858572f9-54f1-4e82-b0a7-12a8009a7821",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Same as Model 4 but using SELU for activation rather than ReLU - supposedly more effective - ELU was not very effective it seemed - High Validation Loss.\n",
    "#also removed batchnormalization and regularization.\n",
    "\n",
    "\n",
    "m5_name = 'm5_TF_3x16_selu'\n",
    "m5_epochs = 250\n",
    "\n",
    "m5 = Sequential([\n",
    "    BatchNormalization(),\n",
    "    \n",
    "    Dense(units = 16, kernel_initializer = 'lecun_normal'),\n",
    "    Activation('selu'),\n",
    "    \n",
    "    Dense(units = 16, kernel_initializer = 'lecun_normal'),\n",
    "    Activation('selu'),\n",
    "    \n",
    "    Dense(units = 16, kernel_initializer = 'lecun_normal'),\n",
    "    Activation('selu'),\n",
    "    \n",
    "    Dense(units = 4, activation = Softmax())\n",
    "])\n",
    "\n",
    "m5.compile(loss = CategoricalCrossentropy(),\n",
    "           optimizer = Adam(),\n",
    "           metrics = [CategoricalCrossentropy(), KLDivergence()]\n",
    "          )\n",
    "m5_history = m5.fit(X_train, y_train,\n",
    "                    validation_data = (X_val, y_val),\n",
    "                    epochs = m5_epochs,\n",
    "                    callbacks = [reduce_lr_on_plateau_half, early_stopping_50]\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a63e4395-303d-432f-8af5-5a1a71e7fca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_model_metrics(m5_name, m5_history)\n",
    "\n",
    "display_confusion_matrix(X_val, X_test, y_val, y_test, m5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1146d19-1582-4a77-b717-05a4e6c4c27f",
   "metadata": {},
   "source": [
    "**SELU Improved performance and both validation and training loss were still decreasing when epoch limit reached, so will increase to 500 for model 6.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f6810ea-d874-41ba-bdfd-a4eb14cf2937",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Same as M5, but now 500 epoch maximum, slightly increased neurons to 18 per layer\n",
    "\n",
    "\n",
    "m6_name = 'm6_TF_3x18_selu'\n",
    "m6_epochs = 500\n",
    "\n",
    "m6 = Sequential([\n",
    "    BatchNormalization(),\n",
    "    \n",
    "    Dense(units = 18, kernel_initializer = 'lecun_normal'),\n",
    "    Activation('selu'),\n",
    "    \n",
    "    Dense(units = 18, kernel_initializer = 'lecun_normal'),\n",
    "    Activation('selu'),\n",
    "    \n",
    "    Dense(units = 18, kernel_initializer = 'lecun_normal'),\n",
    "    Activation('selu'),\n",
    "    \n",
    "    Dense(units = 4, activation = Softmax())\n",
    "])\n",
    "\n",
    "m6.compile(loss = CategoricalCrossentropy(),\n",
    "           optimizer = Adam(),\n",
    "           metrics = [CategoricalCrossentropy(), KLDivergence()]\n",
    "          )\n",
    "m6_history = m6.fit(X_train, y_train,\n",
    "                    validation_data = (X_val, y_val),\n",
    "                    epochs = m6_epochs,\n",
    "                    callbacks = [reduce_lr_on_plateau_half, early_stopping_50]\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f395c1-d53a-46e4-9403-c47c295ab0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_model_metrics(m6_name, m6_history)\n",
    "\n",
    "display_confusion_matrix(X_val, X_test, y_val, y_test, m6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9de5971-f3c3-46c5-acc8-4f071765100d",
   "metadata": {},
   "outputs": [],
   "source": [
    "m7_name = 'm7_TF_3x16_selu'\n",
    "m7_epochs = 500\n",
    "\n",
    "m7 = Sequential([\n",
    "    BatchNormalization(),\n",
    "    \n",
    "    Dense(units = 16, kernel_initializer = 'lecun_normal'),\n",
    "    Activation('selu'),\n",
    "    \n",
    "    Dense(units = 16, kernel_initializer = 'lecun_normal'),\n",
    "    Activation('selu'),\n",
    "    \n",
    "    Dense(units = 16, kernel_initializer = 'lecun_normal'),\n",
    "    Activation('selu'),\n",
    "    \n",
    "    Dense(units = 4, activation = Softmax())\n",
    "])\n",
    "\n",
    "m7.compile(loss = CategoricalCrossentropy(),\n",
    "           optimizer = Adam(),\n",
    "           metrics = [CategoricalCrossentropy(), KLDivergence()]\n",
    "          )\n",
    "m7_history = m7.fit(X_train, y_train,\n",
    "                    validation_data = (X_val, y_val),\n",
    "                    epochs = m7_epochs,\n",
    "                    callbacks = [reduce_lr_on_plateau_half, early_stopping_50]\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2868d3f8-80ad-45ba-adb4-f678f8feeeb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#m8 - same as m6 but with a new reduceLRonplateau, reducing by 1% every 3 epochs if not improving.\n",
    "#This seemed to imrpove performance!! \n",
    "\n",
    "reduce_lr_on_plateau_3 = ReduceLROnPlateau(monitor = 'val_loss',\n",
    "                                           patience = 3,\n",
    "                                           factor = 0.99)\n",
    "\n",
    "m8_name = 'm8_TF_3x16_selu'\n",
    "m8_epochs = 500\n",
    "\n",
    "m8 = Sequential([\n",
    "    BatchNormalization(),\n",
    "    \n",
    "    Dense(units = 16, kernel_initializer = 'lecun_normal'),\n",
    "    Activation('selu'),\n",
    "    \n",
    "    Dense(units = 16, kernel_initializer = 'lecun_normal'),\n",
    "    Activation('selu'),\n",
    "    \n",
    "    Dense(units = 16, kernel_initializer = 'lecun_normal'),\n",
    "    Activation('selu'),\n",
    "    \n",
    "    Dense(units = 4, activation = Softmax())\n",
    "])\n",
    "\n",
    "m8.compile(loss = CategoricalCrossentropy(),\n",
    "           optimizer = Adam(),\n",
    "           metrics = [CategoricalCrossentropy(), KLDivergence()]\n",
    "          )\n",
    "m8_history = m8.fit(X_train, y_train,\n",
    "                    validation_data = (X_val, y_val),\n",
    "                    epochs = m8_epochs,\n",
    "                    callbacks = [reduce_lr_on_plateau_3, early_stopping_50]\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a52aa04e-ae88-4f91-88eb-87ce66de7446",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_model_metrics(m8_name, m8_history)\n",
    "\n",
    "display_confusion_matrix(X_val, X_test, y_val, y_test, m8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab2cadbe-1d6e-4a19-b222-cc09cf09f4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#m9 - same as m8, but slightly more neurons, and a slightly stronger reduceLROnPlateau callback (-2% every 3 epochs)\n",
    "\n",
    "reduce_lr_on_plateau_3_2 = ReduceLROnPlateau(monitor = 'val_loss',\n",
    "                                             patience = 3,\n",
    "                                             factor = 0.98)\n",
    "m9_name = 'm9_TF_3x18_selu'\n",
    "m9_epochs = 500\n",
    "\n",
    "m9 = Sequential([\n",
    "    BatchNormalization(),\n",
    "    \n",
    "    Dense(units = 18, kernel_initializer = 'lecun_normal'),\n",
    "    Activation('selu'),\n",
    "    \n",
    "    Dense(units = 18, kernel_initializer = 'lecun_normal'),\n",
    "    Activation('selu'),\n",
    "    \n",
    "    Dense(units = 18, kernel_initializer = 'lecun_normal'),\n",
    "    Activation('selu'),\n",
    "    \n",
    "    Dense(units = 4, activation = Softmax())\n",
    "])\n",
    "\n",
    "m9.compile(loss = CategoricalCrossentropy(),\n",
    "           optimizer = Adam(),\n",
    "           metrics = [CategoricalCrossentropy(), KLDivergence()]\n",
    "          )\n",
    "m9_history = m9.fit(X_train, y_train,\n",
    "                    validation_data = (X_val, y_val),\n",
    "                    epochs = m9_epochs,\n",
    "                    callbacks = [reduce_lr_on_plateau_3_2, early_stopping_50]\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0fa783d-60be-4d2b-a83c-105033f0dffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_model_metrics(m9_name, m9_history)\n",
    "\n",
    "display_confusion_matrix(X_val, X_test, y_val, y_test, m9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37500144-2196-4d03-81b0-bf39338dcf9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#m10 - Same as m9 but 24 units per layer, and a 4% reduction in lr, as this change previously slightly imporved performance.\n",
    "#This did not seem to work, model did not converge effectively.\n",
    "\n",
    "reduce_lr_on_plateau_3_4 = ReduceLROnPlateau(monitor = 'val_loss',\n",
    "                                             patience = 3,\n",
    "                                             factor = 0.96)\n",
    "m10_name = 'm10_TF_3x24_selu'\n",
    "m10_epochs = 500\n",
    "\n",
    "m10 = Sequential([\n",
    "    BatchNormalization(),\n",
    "    \n",
    "    Dense(units = 24, kernel_initializer = 'lecun_normal'),\n",
    "    Activation('selu'),\n",
    "    \n",
    "    Dense(units = 24, kernel_initializer = 'lecun_normal'),\n",
    "    Activation('selu'),\n",
    "    \n",
    "    Dense(units = 24, kernel_initializer = 'lecun_normal'),\n",
    "    Activation('selu'),\n",
    "    \n",
    "    Dense(units = 4, activation = Softmax())\n",
    "])\n",
    "\n",
    "m10.compile(loss = CategoricalCrossentropy(),\n",
    "           optimizer = Adam(),\n",
    "           metrics = [CategoricalCrossentropy(), KLDivergence()]\n",
    "          )\n",
    "m10_history = m10.fit(X_train, y_train,\n",
    "                    validation_data = (X_val, y_val),\n",
    "                    epochs = m10_epochs,\n",
    "                    callbacks = [reduce_lr_on_plateau_3_4, early_stopping_50]\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be642771-58af-4029-801b-56d5a475875c",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_model_metrics(m10_name, m10_history)\n",
    "\n",
    "display_confusion_matrix(X_val, X_test, y_val, y_test, m10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a378ec21-5e01-4332-a6a4-97fc3fd7a66d",
   "metadata": {},
   "source": [
    "**Model 9 seemed to work best, so will evaluate performance on test set** ~ predicted classes correctly ~74% of the time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e9f2591-68d6-4687-aa41-782df34a49a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "m9.evaluate(X_test, y_test)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
